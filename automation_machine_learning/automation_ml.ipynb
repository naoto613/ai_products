{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from keras import models,layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autometion():\n",
    "    def __init__(self, score, arg1, arg2 = None, arg3 = None, arg4 = None, arg5 = None, arg6 = None, arg7 = None, arg8 = None):\n",
    "        self.score = score\n",
    "        self.arg = [arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8]\n",
    "        i = 7\n",
    "        \n",
    "        # 引数が無ければ削除\n",
    "        for ar in reversed(self.arg):\n",
    "            if ar == None:\n",
    "                self.arg.pop(i)\n",
    "            i -= 1\n",
    "                \n",
    "        \n",
    "\n",
    "    def preparation(self, train, test):\n",
    "    \n",
    "        # trainとtestを結合する前に判別フラグを立てる\n",
    "        train['train_flg'] = 1\n",
    "        test['train_flg'] = 0\n",
    "\n",
    "        # testに答えの列を追加\n",
    "        test[train.columns[1]] = 9\n",
    "\n",
    "        # trainとtestを結合\n",
    "        train_test_combine = pd.concat([train,test],axis=0)\n",
    "\n",
    "        # 削除する行名と列名の格納するリストを定義\n",
    "        delete_row = []\n",
    "        delete_column = []\n",
    "\n",
    "        # 欠損値の割合を計算\n",
    "        percent = 100 * train_test_combine.isnull().sum()/ len(train_test_combine)      \n",
    "\n",
    "        # 特徴量の数だけループ\n",
    "        for i in range(percent.size):\n",
    "            # object型かつカラムに30種類以上のデータが含まれる、または、欠損値が全体の15％以上ある場合列を削除\n",
    "            if (train_test_combine[percent.index[i]].dtype == ('object') \n",
    "            and train_test_combine[percent.index[i]].nunique() >= 30)or percent[i] >= 15:\n",
    "                delete_column.append(percent.index[i])\n",
    "            # 欠損値が存在し、全体の15％以下である場合行を削除\n",
    "            elif percent[i] > 0 and percent[i] < 15:\n",
    "                delete_row.append(percent.index[i])\n",
    "\n",
    "        # 行の削除\n",
    "        for i in delete_row:\n",
    "            train_test_combine = train_test_combine[train_test_combine[i].notnull()]\n",
    "        # 列の削除\n",
    "        for j in delete_column:\n",
    "            train_test_combine = train_test_combine.drop([j], axis=1)\n",
    "\n",
    "        # trainの答えを退避\n",
    "        train_y = train_test_combine[train_test_combine['train_flg'] == 1][train.columns[1]]\n",
    "        # testのIDを退避\n",
    "        test_ID = train_test_combine[train_test_combine['train_flg'] == 0][test.columns[0]]\n",
    "\n",
    "        # ID, 答えを削除\n",
    "        train_test_combine = train_test_combine.drop([train.columns[0],train.columns[1]],axis=1) \n",
    "\n",
    "        # カテゴリカル変数の特徴量だけを抽出\n",
    "        categorical_columns = [c for c in train_test_combine.columns if (train_test_combine[c].dtype != ('float64') \n",
    "                                                                         and train_test_combine[c].dtype != ('int64') \n",
    "                                                                         and train_test_combine[c].dtype != ('bool'))]\n",
    "\n",
    "        # カテゴリカル変数の種類と個数を出力し、one-hot-encoding\n",
    "        for col in categorical_columns:\n",
    "            ohe = pd.get_dummies(train_test_combine[col],drop_first=True)\n",
    "            train_test_combine = train_test_combine.drop([col],axis=1)\n",
    "            train_test_combine = pd.concat([train_test_combine,ohe], axis=1)\n",
    "\n",
    "        train = train_test_combine[train_test_combine['train_flg'] == 1].drop(['train_flg'], axis=1)\n",
    "        test = train_test_combine[train_test_combine['train_flg'] == 0].drop(['train_flg'], axis=1)\n",
    "\n",
    "        return train, train_y, test, test_ID\n",
    "    \n",
    "    def evaluation(self, x, y, ranking, arg):\n",
    "\n",
    "        for i in arg:\n",
    "            if i == 'logisticRegression':\n",
    "                ranking = self.logistic(x, y, ranking)\n",
    "            elif i == 'SVC':\n",
    "                ranking = self.SVCK(x, y, ranking)\n",
    "            elif i == 'naiveBayes':\n",
    "                ranking = self.naive(x, y, ranking)\n",
    "            elif i == 'randomForest':\n",
    "                ranking = self.randomForest(x, y, ranking)\n",
    "            elif i == 'xgboost':\n",
    "                ranking = self.XGboost(x, y, ranking)\n",
    "            elif i == 'adaboost':\n",
    "                ranking = self.ADAboost(x, y, ranking)\n",
    "            elif i == 'neuralNet':\n",
    "                ranking = self.NeuralNet(x, y, ranking)\n",
    "            elif i == 'KNeighborsClassifier':\n",
    "                ranking = self.KNeighber(x, y, ranking)\n",
    "            else:\n",
    "                print(i + 'は対応していません')\n",
    "\n",
    "        return ranking\n",
    "    \n",
    "    def logistic(self, x, y, ranking):\n",
    "        #ロジスティック回帰\n",
    "        logistic_regression = LogisticRegressionCV(random_state=0, penalty='l2', Cs=10, n_jobs=-1)\n",
    "        answer = cross_val_score(logistic_regression, x, y, scoring = self.score)\n",
    "        ranking['ロジスティック回帰'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def SVCK(self, x, y, ranking):\n",
    "        #サポートベクトルマシン\n",
    "        svc = SVC(C=1.0,kernel='linear',probability=True,random_state=0)\n",
    "        answer = cross_val_score(svc, x, y, scoring = self.score)\n",
    "        ranking['サポートベクトルマシン'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def naive(self, x, y, ranking):\n",
    "        #ナイーブベイズ\n",
    "        naive = GaussianNB()\n",
    "        answer = cross_val_score(naive, x, y, scoring = self.score)\n",
    "        ranking['ナイーブベイズ'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def randomForest(self, x, y, ranking):\n",
    "        #ランダムフォレスト\n",
    "        RF = RandomForestClassifier(criterion='gini', n_estimators=25, random_state=0, n_jobs=-1)\n",
    "        answer = cross_val_score(RF, x, y, scoring = self.score)\n",
    "        ranking['ランダムフォレスト'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def XGboost(self, x, y, ranking):\n",
    "        #Xgboost\n",
    "        xgboost = xgb.XGBClassifier()\n",
    "        answer = cross_val_score(xgboost, x, y, scoring = self.score)\n",
    "        ranking['XGブースト'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def ADAboost(self, x, y, ranking):\n",
    "        #ADAブースト\n",
    "        adaboost = AdaBoostClassifier(random_state=0)\n",
    "        answer = cross_val_score(adaboost, x, y, scoring = self.score)\n",
    "        ranking['ADAブースト'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def KNeighber(self, x, y, ranking):\n",
    "        #K近傍法\n",
    "        Knn = KNeighborsClassifier()\n",
    "        answer = cross_val_score(Knn, x, y, scoring =self.score)\n",
    "        ranking['K近傍法'] = np.average(answer)\n",
    "        return ranking\n",
    "    \n",
    "    def NeuralNet(self, x, y, ranking):\n",
    "        # ニューラルネット\n",
    "        if self.score != 'accuracy':\n",
    "            print('NNを使う場合の評価関数はaccuracyのみのため、NNをランキングに含めません。')\n",
    "            return ranking\n",
    "        \n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(units=32, activation='relu', input_shape=(X_train[0].size,)))\n",
    "        model.add(layers.Dense(units=64, activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer = \"rmsprop\", metrics=[self.score])\n",
    "\n",
    "        # 早期終了を行うコールバック関数を設定\n",
    "        callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2)]\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=20, verbose=0, callbacks = callbacks, batch_size=100) \n",
    "        loss, scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "        ranking['ニューラルネット'] = scores\n",
    "        return ranking\n",
    "    \n",
    "    def result(self, x, y, xt, test_ID, score, ranking):\n",
    "        # ランキングを表示\n",
    "        print(\"評価指標：\" + score)\n",
    "        print()\n",
    "        print(\"アルゴリズムランキング\")\n",
    "        j = 1\n",
    "\n",
    "        for k, i in ranking:\n",
    "            print(str(j) + \"位：\" + k,end=\"\")\n",
    "            print(\"（\" ,end=\"\")\n",
    "            print(i, end=\"\")\n",
    "            print(\"）\")\n",
    "            if j == 1:\n",
    "                if k == 'ニューラルネット':\n",
    "                    model = models.Sequential()\n",
    "                    model.add(layers.Dense(units=32, activation='relu', input_shape=(x[0].size,)))\n",
    "                    model.add(layers.Dense(units=64, activation='relu'))\n",
    "                    model.add(layers.Dropout(0.2))\n",
    "                    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "                    callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "                                 ModelCheckpoint(filepath = \"best_model.h5\",monitor = \"val_loss\", save_best_only = True)]\n",
    "                    model.compile(loss=\"binary_crossentropy\", optimizer = \"rmsprop\", metrics=[score])\n",
    "                    model.fit(x, y, epochs=20, verbose=0, callbacks = callbacks, batch_size=100,validation_split=0.3) \n",
    "                    predicted = model.predict(xt)\n",
    "                    answer= pd.concat([test_ID, pd.DataFrame(predicted)],axis = 1)\n",
    "                    if os.path.isfile('best_model.pkl'):\n",
    "                        os.remove('best_model.pkl')\n",
    "\n",
    "                else:\n",
    "                    if k == 'ロジスティック回帰':\n",
    "                        model = LogisticRegressionCV(random_state=0, penalty='l2', Cs=10, n_jobs=-1).fit(x,y)\n",
    "                    elif k == 'サポートベクトルマシン':\n",
    "                        model = SVC(C=1.0,kernel='linear',probability=True,random_state=0).fit(x,y)\n",
    "                    elif k == 'ナイーブベイズ':\n",
    "                        model = CalibratedClassifierCV(GaussianNB(), cv=2, method='sigmoid')\n",
    "                    elif k == 'ランダムフォレスト':\n",
    "                        model = RandomForestClassifier(criterion='gini', n_estimators=25, random_state=0, n_jobs=-1).fit(x,y)\n",
    "                    elif k == 'XGブースト':\n",
    "                        model = xgb.XGBClassifier().fit(x,y)\n",
    "                    elif k == 'ADAブースト':\n",
    "                        model = AdaBoostClassifier(random_state=0).fit(x,y)\n",
    "                    elif k == 'K近傍法':\n",
    "                        model = KNeighborsClassifier().fit(x,y)\n",
    "\n",
    "\n",
    "                    joblib.dump(model, \"best_model.pkl\")\n",
    "                    predicted = model.predict_proba(xt)\n",
    "                    answer = pd.concat([test_ID, pd.DataFrame(predicted)[1]],axis = 1)\n",
    "                    answer.columns = ['ID','predicted']\n",
    "                    if os.path.isfile('best_model.h5'):\n",
    "                        os.remove('best_model.h5')\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        answer.to_csv(\"answer.csv\",index=False)\n",
    "        \n",
    "    def run(self):\n",
    "        # データの読み込み\n",
    "        train = pd.read_csv(\"train.csv\")\n",
    "        test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "        # データの準備\n",
    "        train_x, train_y, test, test_ID = self.preparation(train, test)\n",
    "\n",
    "        # 正規化\n",
    "        scaler = StandardScaler()\n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test = scaler.fit_transform(test)\n",
    "\n",
    "        #　アルゴリズムの結果を格納するリスト\n",
    "        ranking = {}\n",
    "\n",
    "        ranking = self.evaluation(train_x, train_y, ranking, self.arg)\n",
    "\n",
    "        # アルゴリズムをランキング形式で並べ替え\n",
    "        ranking = sorted(ranking.items(), key=lambda x:-x[1])\n",
    "\n",
    "        # 結果\n",
    "        self.result(train_x, train_y, test, test_ID, self.score, ranking)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一引数\n",
    "# 評価関数\n",
    "# accuracy\n",
    "# precision\n",
    "# recall\n",
    "# f1\n",
    "# ※ニューラルネットを使う場合はaccuracyのみ\n",
    "\n",
    "# 第2-8引数\n",
    "# アルゴリズム\n",
    "# logisticRegression\n",
    "# SVC\n",
    "# naiveBayes\n",
    "# randomForest\n",
    "# xgboost\n",
    "# adaboost\n",
    "# neuralNet\n",
    "# KNeighborsClassifier\n",
    "auntomation = Autometion('accuracy','xgboost','neuralNet','randomForest', 'logisticRegression')\n",
    "\n",
    "# 実行\n",
    "auntomation.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
