{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from pykakasi import kakasi\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GRU, Input, Masking\n",
    "from keras.callbacks import EarlyStopping \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "# 同じ階層に\"bot.txt\"を準備\n",
    "with open(\"bot.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
    "    bot_original = f.read()\n",
    "\n",
    "\n",
    "bot = re.sub(\"[\\n]\", \"。\", bot_original) # | と全角半角スペース、「」と改行の削除\n",
    "bot = re.sub(\"[｜ 　]\", \"\", bot) # | と全角半角スペース、「」と改行の削除\n",
    "\n",
    "bot = bot.replace('！。', '！')\n",
    "bot = bot.replace('？。', '？')\n",
    "bot = bot.replace('♪。', '♪')\n",
    "bot = bot.replace('？*', '？')\n",
    "bot = bot.replace('♪？', '♪')\n",
    "bot = bot.replace('。*', '。')\n",
    "\n",
    "print(\"文字数:\", len(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperator = \"。\"  # 。をセパレータに指定\n",
    "bot_list = re.split('[。！？♪]', bot)  # セパレーターを使って文章をリストに分割する\n",
    "bot_list.pop() # 最後の要素は空の文字列になるので、削除\n",
    "bot_list.pop(0)\n",
    "bot_list = [x+seperator for x in bot_list]  # 文章の最後に。を追加\n",
    "\n",
    "kakasi = kakasi()\n",
    "kakasi.setMode(\"J\", \"H\")  # J(漢字) からH(ひらがな)へ\n",
    "conv = kakasi.getConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kana_text = conv.do(bot)  # 全体をひらがなに変換\n",
    "print(set(kana_text))  # set()で文字の重複をなくす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kana_bot.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(kana_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiragana = \"ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞ\\\n",
    "ただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽ\\\n",
    "まみむめもゃやゅゆょよらりるれろゎわゐゑをん\"\n",
    "\n",
    "katakana = \"ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾ\\\n",
    "タダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポ\\\n",
    "マミムメモャヤュユョヨラリルレロヮワヰヱヲンヴ\"\n",
    "\n",
    "chars = hiragana + katakana\n",
    "\n",
    "with open(\"kana_bot.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # 前回保存したファイル\n",
    "    text = f.read()\n",
    "    \n",
    "for char in text:  # ひらがな、カタカナ以外でコーパスに使われている文字を追加\n",
    "    if char not in chars:\n",
    "        chars += char\n",
    "        \n",
    "chars += \"\\t\\n\"  # タブと改行を追加\n",
    "        \n",
    "chars_list = sorted(list(chars))  # 文字列をリストに変換してソートする\n",
    "print(chars_list)\n",
    "\n",
    "with open(\"kana_chars.pickle\", mode=\"wb\") as f:  # pickleで保存\n",
    "    pickle.dump(chars_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスと文字で辞書を作成\n",
    "char_indices = {}  # 文字がキーでインデックスが値\n",
    "for i, char in enumerate(chars_list):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}  # インデックスがキーで文字が値\n",
    "for i, char in enumerate(chars_list):\n",
    "    indices_char[i] = char\n",
    "    \n",
    "seperator = \"。\"\n",
    "\n",
    "sentence_list = re.split('[。！？♪]', text)  # セパレーターを使って文章をリストに分割する\n",
    "sentence_list.pop() \n",
    "sentence_list = [x+seperator for x in sentence_list]\n",
    "\n",
    "max_sentence_length = 128  # 文章の最大長さ。これより長い文章はカットされる。\n",
    "sentence_list = [sentence for sentence in sentence_list if len(sentence) <= max_sentence_length]  # 長すぎる文章のカット\n",
    "\n",
    "n_char = len(chars_list)  # 文字の種類の数\n",
    "n_sample = len(sentence_list) - 1  # サンプル数\n",
    "\n",
    "x_sentences = []  # 入力の文章\n",
    "t_sentences = []  # 正解の文章\n",
    "for i in range(n_sample):\n",
    "    x_sentences.append(sentence_list[i])\n",
    "    t_sentences.append(\"\\t\" + sentence_list[i+1] + \"\\n\")  # 正解は先頭にタブ、末尾に改行を加える\n",
    "max_length_x = max_sentence_length  # 入力文章の最大長さ\n",
    "max_length_t = max_sentence_length + 2  # 正解文章の最大長さ\n",
    "\n",
    "x_encoder = np.zeros((n_sample, max_length_x, n_char), dtype=np.bool)  # encoderへの入力\n",
    "x_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderへの入力\n",
    "t_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderの正解\n",
    "\n",
    "for i in range(n_sample):\n",
    "    x_sentence = x_sentences[i]\n",
    "    t_sentence = t_sentences[i]\n",
    "    for j, char in enumerate(x_sentence):\n",
    "        x_encoder[i, j, char_indices[char]] = 1  # encoderへの入力をone-hot表現で表す\n",
    "    for j, char in enumerate(t_sentence):\n",
    "        x_decoder[i, j, char_indices[char]] = 1  # decoderへの入力をone-hot表現で表す\n",
    "        if j > 0:  # 正解は入力より1つ前の時刻のものにする\n",
    "            t_decoder[i, j-1, char_indices[char]] = 1\n",
    "            \n",
    "print(x_encoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 150\n",
    "n_mid = 128  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None, n_char))\n",
    "encoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
    "encoder_masked = encoder_mask(encoder_input)\n",
    "encoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_state=True)  # dropoutを設定し、ニューロンをランダムに無効にする\n",
    "encoder_output, encoder_state_h = encoder_lstm(encoder_masked)\n",
    "\n",
    "decoder_input = Input(shape=(None, n_char))\n",
    "decoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
    "decoder_masked = decoder_mask(decoder_input)\n",
    "decoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True)  # dropoutを設定\n",
    "decoder_output, _ = decoder_lstm(decoder_masked, initial_state=encoder_state_h)  # encoderの状態を初期状態にする\n",
    "decoder_dense = Dense(n_char, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_lossに改善が見られなくなってから、10エポックで学習は終了\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10) \n",
    "\n",
    "history = model.fit([x_encoder, x_decoder], t_decoder,\n",
    "                     batch_size=64,\n",
    "                     epochs=150,\n",
    "                     validation_split=0.1,  # 10%は検証用\n",
    "                     callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss)), loss)\n",
    "plt.plot(np.arange(len(val_loss)), val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoderのモデル\n",
    "encoder_model = Model(encoder_input, encoder_state_h)\n",
    "\n",
    "# decoderのモデル\n",
    "decoder_state_in_h = Input(shape=(n_mid,))\n",
    "decoder_state_in = [decoder_state_in_h]\n",
    "\n",
    "decoder_output, decoder_state_h = decoder_lstm(decoder_input,\n",
    "                                               initial_state=decoder_state_in_h)\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "decoder_model = Model([decoder_input] + decoder_state_in,\n",
    "                      [decoder_output, decoder_state_h])\n",
    "\n",
    "# モデルの保存\n",
    "encoder_model.save('encoder_model.h5')\n",
    "decoder_model.save('decoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(input_data, beta=5):\n",
    "    state_value = encoder_model.predict(input_data)\n",
    "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
    "    y_decoder[0][0][char_indices[\"\\t\"]] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
    "\n",
    "    respond_sentence = \"\"  # 返答の文字列\n",
    "    while True:\n",
    "        y, h = decoder_model.predict([y_decoder, state_value])\n",
    "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
    "        next_char = indices_char[next_index]  # 次の文字\n",
    "\n",
    "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
    "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
    "            \n",
    "        respond_sentence += next_char\n",
    "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
    "        y_decoder[0][0][next_index] = 1\n",
    "\n",
    "        state_value = h  # 次の時刻の状態\n",
    "\n",
    "    return respond_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスと文字で辞書を作成\n",
    "char_indices = {}\n",
    "for i, char in enumerate(chars_list):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}\n",
    "for i, char in enumerate(chars_list):\n",
    "    indices_char[i] = char\n",
    "    \n",
    "n_char = len(chars_list)\n",
    "max_length_x = 128\n",
    "\n",
    "# 文章をone-hot表現に変換する関数\n",
    "def sentence_to_vector(sentence):\n",
    "    vector = np.zeros((1, max_length_x, n_char), dtype=np.bool)\n",
    "    for j, char in enumerate(sentence):\n",
    "        vector[0][j][char_indices[char]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = load_model('encoder_model.h5')\n",
    "decoder_model = load_model('decoder_model.h5')\n",
    "\n",
    "def respond(input_data, beta=2):\n",
    "    state_value = encoder_model.predict(input_data)\n",
    "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
    "    y_decoder[0][0][char_indices['\\t']] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
    "\n",
    "    respond_sentence = \"\"  # 返答の文字列\n",
    "    while True:\n",
    "        y, h = decoder_model.predict([y_decoder, state_value])\n",
    "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
    "        next_char = indices_char[next_index]  # 次の文字\n",
    "        \n",
    "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
    "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
    "            \n",
    "        respond_sentence += next_char\n",
    "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
    "        y_decoder[0][0][next_index] = 1\n",
    "\n",
    "        state_value = h  # 次の時刻の状態\n",
    "\n",
    "    return respond_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a = \"こんにちは。\"\n",
    "response_b = \"\"\n",
    "for i in range(10):\n",
    "    print(\"A君:\", response_a)\n",
    "    print()  \n",
    "    vector_a = sentence_to_vector(response_a)\n",
    "    \n",
    "    response_b = respond(vector_a)\n",
    "    print(\"B君:\", response_b)\n",
    "    print()\n",
    "    vector_b = sentence_to_vector(response_b)\n",
    "    \n",
    "    response_a = respond(vector_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
